
# Object Detection for Visually Impaired Using TensorFlow Model

This project is an Android application designed to assist visually impaired users by leveraging TensorFlow Lite for real-time object detection. The app provides auditory feedback about the location of detected objects, enhancing spatial awareness and aiding in navigation.

## üåü Features

- **TensorFlow Lite Object Detection**: Utilizes a pre-trained machine learning model for accurate and efficient object detection on mobile devices.
- **Spatial Localization**: Announces the location of detected objects, specifying whether they are on the left or right side of the user.
- **User-Friendly Interface**: Designed with accessibility in mind, ensuring a seamless experience for visually impaired users.
- **Real-Time Feedback**: Delivers instant spoken feedback to improve user awareness and safety.

## üõ†Ô∏è Technologies

- **Languages**: Java, XML (for Android development)
- **Frameworks and Libraries**: TensorFlow Lite, Android SDK
- **Tools**: Android Studio, TensorFlow Model Maker

## üöÄ Getting Started

### Prerequisites

- Android device with a camera
- Internet connection (for initial setup and potential model updates)
- Android Studio installed on your computer

### Installation

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/dhanushba/object-detection-for-visually-impaired-using-tensorflowmodel.git
   cd object-detection-for-visually-impaired-using-tensorflowmodel
   ```

2. **Open the Project in Android Studio**:
   - Launch Android Studio.
   - Open the project by selecting the folder where the repository was cloned.

3. **Install Dependencies**:
   - Ensure all necessary dependencies and libraries are installed via Gradle.

4. **Build and Run the Application**:
   - Connect your Android device to your computer.
   - Click "Run" in Android Studio to build and deploy the app to your device.

## üéØ Usage

1. **Launch the App**: Open the app on your Android device.
2. **Grant Necessary Permissions**: Ensure the app has access to the camera and microphone.
3. **Use the Camera**: Point the device camera towards objects of interest.
4. **Receive Feedback**: The app will provide real-time auditory feedback, informing you about the objects detected and their location.

## ü§ù Contributing

Contributions are welcome! Feel free to submit issues or pull requests to help improve the application and add new features.

## üìÑ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

